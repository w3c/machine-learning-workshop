<div class="talks"><details class=talk><summary><div class="grid"><a href="talks/web_platform_a_30_000_feet_view_web_platform_and_js_environment_constraints.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdo77h2f4st7077212hxr6v7/thumbs/thumb-001.jpeg" alt="Watch Web Platform: a 30,000 feet view / Web Platform and JS environment constraints" width=200 class="tn"></a><a href="talks/web_platform_a_30_000_feet_view_web_platform_and_js_environment_constraints.html">Web Platform: a 30,000 feet view / Web Platform and JS environment constraints</a><span class="summary"> by Dominique Hazaël-Massieux (W3C) - 10 min <span></span></span></div></summary><p><a href="talks/web_platform_a_30_000_feet_view_web_platform_and_js_environment_constraints.html">10 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Dominique Hazaël-Massieux (W3C)</dd><dd>    Dominique is part of the full-time technical staff employed by W3C to animate the Web standardization work. He is in particular responsible for the work on WebRTC, WebXR and Web & Networks, led the effort to start a WebTransport Working Group and is one of the organizers of the Web and Machine Learning workshop.</dd><dt>Abstract</dt><dd>    Background talk on the specificities of the Web browser as a development platform.</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/media_processing_hooks_for_the_web.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdo86r7h5725077210nfqpeg/thumbs/thumb-007.jpeg" alt="Watch Media processing hooks for the Web" width=200 class="tn"></a><a href="talks/media_processing_hooks_for_the_web.html">Media processing hooks for the Web</a><span class="summary"> by François Daoust (W3C) - 12 min <span></span></span></div></summary><p><a href="talks/media_processing_hooks_for_the_web.html">12 minutes presentation</a></p><dl><dt>Speaker</dt><dd>François Daoust (W3C)</dd><dd>François is part of the full-time technical staff employed by W3C and supervizes there the work related to media technologies.</dd><dt>Abstract</dt><dd>This talk will provide an overview of existing, planned or possible hooks for processing muxed and demuxed media (audio and video) in real time in Web applications, and rendering the results. It will also present high-level requirements for efficient media processing.</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/access_purpose_built_ml_hardware_with_web_neural_network_api.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdo75ck44sip0772u0gj0kog/thumbs/thumb-006.jpeg" alt="Watch Access purpose-built ML hardware with Web Neural Network API" width=200 class="tn"></a><a href="talks/access_purpose_built_ml_hardware_with_web_neural_network_api.html">Access purpose-built ML hardware with Web Neural Network API</a><span class="summary"> by Ningxin Hu (Intel) - 10 min <span></span></span></div></summary><p><a href="talks/access_purpose_built_ml_hardware_with_web_neural_network_api.html">10 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Ningxin Hu (Intel)</dd><dd>Ningxin is a principal software engineer at Intel. Ningxin is co-editing the Web Neural Network (WebNN) API spec within W3C Machine Learning for the Web Community Group.</dd><dt>Abstract</dt><dd>The WebNN API is a new web standard proposal that allows web apps and frameworks to accelerate deep neural networks with dedicated on-device hardware such as GPUs, CPUs with deep learning extensions, or purpose-built AI accelerators. A prototype of WebNN API will be used to demonstrate the near-native speed of deep neural network execution for object detection by accessing AI accelerators on phone and PC.</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/a_proposed_web_standard_to_load_and_run_ml_models_on_the_web.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdocr5ma7m0y0772d7i5jkub/thumbs/thumb-002.jpeg" alt="Watch A proposed web standard to load and run ML models on the web" width=200 class="tn"></a><a href="talks/a_proposed_web_standard_to_load_and_run_ml_models_on_the_web.html">A proposed web standard to load and run ML models on the web</a><span class="summary"> by Jonathan Bingham (Google) - 10 min <span></span></span></div></summary><p><a href="talks/a_proposed_web_standard_to_load_and_run_ml_models_on_the_web.html">10 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Jonathan Bingham (Google)</dd><dd>Jonathan is a web product manager at Google.</dd><dt>Abstract</dt><dd>The Model Loader API is a new proposal for a web standard to make it easy to load and run ML models from JavaScript, taking advantage of available hardware acceleration. The API surface is similar to existing model serving APIs (like TensorFlow Serving, TensorRT, and MXNet Model Server), and it is complementary to the Web NN graph API proposal as well as lower level WebGL and WebGPU APIs.</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/simd_operations_in_webgpu_for_ml.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/cke8ahza81hlp0731tiz1d295/thumbs/thumb-002.jpeg" alt="Watch SIMD operations in WebGPU for ML" width=200 class="tn"></a><a href="talks/simd_operations_in_webgpu_for_ml.html">SIMD operations in WebGPU for ML</a><span class="summary"> by Mehmet Oguz Derin - 5 min <span></span></span></div></summary><p><a href="talks/simd_operations_in_webgpu_for_ml.html">5 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Mehmet Oguz Derin</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/accelerated_graphics_and_compute_api_for_machine_learning_directml.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdobv3o075l707723b397arm/thumbs/thumb-004.jpeg" alt="Watch Accelerated graphics and compute API for Machine Learning - DirectML" width=200 class="tn"></a><a href="talks/accelerated_graphics_and_compute_api_for_machine_learning_directml.html">Accelerated graphics and compute API for Machine Learning - DirectML</a><span class="summary"> by Chai Chaoweeraprasit (Microsoft) - 10 min <span></span></span></div></summary><p><a href="talks/accelerated_graphics_and_compute_api_for_machine_learning_directml.html">10 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Chai Chaoweeraprasit (Microsoft)</dd><dd>Chai leads development of machine learning platform at Microsoft</dd><dt>Abstract</dt><dd>DirectML is Microsoft's hardware-accelerated machine learning platform that powers popular frameworks such as TensorFlow and ONNX Runtime. It expands the framework's hardware footprint by enabling high-performance training and inference on any device with DirectX-capable GPU</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/accelerate_ml_inference_on_mobile_devices_with_android_nnapi.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdo78esr4t0j0772i5r7h1td/thumbs/thumb-001.jpeg" alt="Watch Accelerate ML inference on mobile devices with Android NNAPI" width=200 class="tn"></a><a href="talks/accelerate_ml_inference_on_mobile_devices_with_android_nnapi.html">Accelerate ML inference on mobile devices with Android NNAPI</a><span class="summary"> by Miao Wang (Google) - 7 min <span></span></span></div></summary><p><a href="talks/accelerate_ml_inference_on_mobile_devices_with_android_nnapi.html">7 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Miao Wang (Google)</dd><dd>    Software Engineer for Android Neural Networks API</dd><dt>Abstract</dt><dd>The Android Neural Networks API (NNAPI) is an Android C API designed for running computationally intensive operations for machine learning on Android devices. NNAPI is designed to provide a base layer of functionality for higher-level machine learning frameworks, such as TensorFlow Lite and Caffe2, that build and train neural networks. The API is available on all Android devices running Android 8.1 (API level 27) or higher. Based on an app’s requirements and the hardware capabilities on an Android device, NNAPI can efficiently distribute the computation workload across available on-device processors, including dedicated neural network hardware (NPUs and TPUs), graphics processing units (GPUs), and digital signal processors (DSPs).</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/heterogeneous_parallel_programming_with_open_standards_using_oneapi_and_data_parallel_c_.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckeijprvxa4pq07313u8gw5kd/thumbs/thumb-001.jpeg" alt="Watch Heterogeneous parallel programming with open standards using oneAPI and Data Parallel C++" width=200 class="tn"></a><a href="talks/heterogeneous_parallel_programming_with_open_standards_using_oneapi_and_data_parallel_c_.html">Heterogeneous parallel programming with open standards using oneAPI and Data Parallel C++</a><span class="summary"> by Jeff Hammond (Intel) - 12 min <span></span></span></div></summary><p><a href="talks/heterogeneous_parallel_programming_with_open_standards_using_oneapi_and_data_parallel_c_.html">12 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Jeff Hammond (Intel)</dd><dd>Jeff Hammond is a Principal Engineer at Intel where he works on a wide range of high-performance computing topics, including parallel programming models, system architecture and open-source software. He has published more than 60 journal and conference papers on parallel computing, computational chemistry, and linear algebra software. Jeff received his PhD in Physical Chemistry from the University of Chicago.</dd><dt>Abstract</dt><dd>Diversity in computer architecture and the unceasing demand for application performance in data-intensive workloads are never-ending challenges for programmers. This talk will describe Intel’s oneAPI initiative, which is an open ecosystem for heterogeneous computing that supports high-performance data analytics, machine learning and other workloads. A key component of this is Data Parallel C++, which is based on C++17 and Khronos SYCL and supports direct programming of CPU, GPU and FPGA platforms. We will describe how oneAPI and Data Parallel C++ can be used to build high-performance applications for a range of devices.</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/enabling_distributed_dnns_for_the_mobile_web_over_cloud_edge_and_end_devices.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdobyv0p76q107720jc58j6h/thumbs/thumb-002.jpeg" alt="Watch Enabling Distributed DNNs for the Mobile Web Over Cloud, Edge and End Devices" width=200 class="tn"></a><a href="talks/enabling_distributed_dnns_for_the_mobile_web_over_cloud_edge_and_end_devices.html">Enabling Distributed DNNs for the Mobile Web Over Cloud, Edge and End Devices</a><span class="summary"> by Yakun Huang & Xiuquan Qiao (BPTU) - 9 min <span></span></span></div></summary><p><a href="talks/enabling_distributed_dnns_for_the_mobile_web_over_cloud_edge_and_end_devices.html">9 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Yakun Huang & Xiuquan Qiao (BPTU)</dd><dt>Abstract</dt><dd>    This talk introduces two deep learning technologies for the mobile web over cloud, edge and end devices. One is an adaptive DNN execution scheme, which partitions and performs the computation that can be done within the mobile web, reducing the computing pressure of the edge cloud. The other is a lightweight collaborative DNN over cloud, edge and devices, which provides a collaborative mechanism with the edge cloud for accurate compensation.</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/collaborative_learning.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdobw6x0764l07729krgy57d/thumbs/thumb-001.jpeg" alt="Watch Collaborative Learning" width=200 class="tn"></a><a href="talks/collaborative_learning.html">Collaborative Learning</a><span class="summary"> by Wolfgang Maß (DFKI) - 10 min <span></span></span></div></summary><p><a href="talks/collaborative_learning.html">10 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Wolfgang Maß (DFKI)</dd><dd>    Professor at Saarland University and scientific director at DFKI</dd><dt>Abstract</dt><dd>    The execution of data analysis services in a browser on devices has recently gained momentum, but the lack of computing resources on devices and data protection regulations are forcing strong constraints. In our talk we will present a browser-based collaborative learning approach for running data analysis services on peer-to-peer networks of devices. Our platform is developed in Javascript, supports modularization of services, model training and usage on devices (tensorflow.js), sensor communication (mqtt), and peer-to-peer communication (WebRTC) with role-based access-control (oauth 2.0).</dd></dl></details>
<details class=talk><summary><div class="grid"><a href="talks/introducing_wasi_nn.html"><img src="https://cjx1uopmt0m4q0667xmnrqpk.blob.core.windows.net/ckdobysfk76ns0772a6u4dbq5/thumbs/thumb-001.jpeg" alt="Watch Introducing WASI-NN" width=200 class="tn"></a><a href="talks/introducing_wasi_nn.html">Introducing WASI-NN</a><span class="summary"> by Mingqiu Sun & Andrew Brown (Intel) - 7 min <span></span></span></div></summary><p><a href="talks/introducing_wasi_nn.html">7 minutes presentation</a></p><dl><dt>Speaker</dt><dd>Mingqiu Sun & Andrew Brown (Intel)</dd><dd>    Senior PE at Intel & software engineer at Intel</dd><dt>Abstract</dt><dd>    Trained machine learning models are typically deployed on a variety of devices with different architectures and operating systems. WebAssembly provides an ideal portable form of deployment for those models. In this talk, we will introduce the WASI-NN initiative we have started in the WebAssembly System Interface (WASI) community, which would standardize the neural network system interface for WebAssembly programs.</dd></dl></details>
</dl>