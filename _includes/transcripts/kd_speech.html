<div class="slide" role='region' aria-label="Slide 1 of 13" id="slide-1" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=1"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=1">Slide 1</a></noscript></div><div role='region'><p>Hello. I am Kelly Davis, the manager of the Mozilla Machine Learning Group.</p>
<p>The title of my talk is Wreck a Nice Beach in the Browser: Getting the Browser to Recognize Speech.</p>
<p>So with an eye on the clock, let's get started.</p></div><div class="slide" role='region' aria-label="Slide 2 of 13" id="slide-2" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=2"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=2">Slide 2</a></noscript></div><div role='region'><p>Here's the general outline of my talk.</p>
<p>I'll begin with a quick introduction to speech recognition in the browser.</p>
<p>And follow that with a few words on the standardization, or lack thereof, of our browser-based speech recognition API.</p>
<p>Next, I'll move on to examine some of the hurdles, privacy issues that arise when one attempts to bring speech recognition to the browser.</p>
<p>After that, I have a few words to say on the implementation details of speech to text in the browser, to embed or not to embed the speech recognition engine into the browser.</p>
<p>Finally, I'll conclude with some words on the current lay of the land for browser-based speech recognition.</p></div><div class="slide" role='region' aria-label="Slide 3 of 13" id="slide-3" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=3"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=3">Slide 3</a></noscript></div><div role='region'><p>So let us begin at the beginning with an introduction to speech recognition in the browser.</p></div><div class="slide" role='region' aria-label="Slide 4 of 13" id="slide-4" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=4"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=4">Slide 4</a></noscript></div><div role='region'><p>As I'm sure you're well aware, there are numerous browser-based APIs from Web Audio to Web Workers, however, the Web Speech API, the API which is responsible for exposing speech recognition in the browser, is a bit behind the curve.</p>
<p>It's still only a draft community group report but it's already old.</p>
<p>It's been around about 10 years.</p>
<p>So speech in the browser is, despite its age, still rather immature.</p></div><div class="slide" role='region' aria-label="Slide 5 of 13" id="slide-5" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=5"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=5">Slide 5</a></noscript></div><div role='region'><p>One reason for its immaturity is the struggle over standardization.</p></div><div class="slide" role='region' aria-label="Slide 6 of 13" id="slide-6" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=6"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=6">Slide 6</a></noscript></div><div role='region'><p>The current Web Speech API reflects the times in which it was originally written about 10 years ago.</p>
<p>In particular, it doesn't make use of the subsequent advances in, for example, the Web Audio API. In addition, there are some privacy issues the API exposes that still need to be addressed.</p></div><div class="slide" role='region' aria-label="Slide 7 of 13" id="slide-7" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=7"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=7">Slide 7</a></noscript></div><div role='region'><p>Questions of privacy that were present in the original API and new ones that arose since the original was written nip at the heels of standardization.</p></div><div class="slide" role='region' aria-label="Slide 8 of 13" id="slide-8" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=8"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=8">Slide 8</a></noscript></div><div role='region'><p>For example, speech recognition exposes GDPR issues.</p>
<p>If speech recognition happens server side, as it does in the vast majority of cases, and your speech is retained to help train future speech recognition engines, as is now a standard in the industry, how is the GDPR right of erasure implemented?</p>
<p>The current Web Speech API is silent on this point.</p>
<p>Also, if your speech is retained, as it is for the majority of server-based speech recognition engines, how is the GDPR right of access implemented?</p>
<p>The current Web Speech API is silent on this point too.</p>
<p>At the core of these issues is the issue of consent.</p>
<p>How does the Web Speech API handle the issues of consent that arise when speech data is stored and reused server side?</p>
<p>For the future of the Web Speech API, it is critical to address these privacy issues.</p></div><div class="slide" role='region' aria-label="Slide 9 of 13" id="slide-9" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=9"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=9">Slide 9</a></noscript></div><div role='region'><p>However, some of these privacy issues can be addressed by addressing the question of whether to embed or not to embed.</p>
<p>Whether to embed the speech recognition engine client side or to keep it server side as is current common practice.</p></div><div class="slide" role='region' aria-label="Slide 10 of 13" id="slide-10" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=10"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=10">Slide 10</a></noscript></div><div role='region'><p>Answering the question to embed or not to embed involves a number of trade-offs.</p>
<p>Embedding improves latency: responses are almost immediate.</p>
<p>Privacy and security: the data never leaves your machine.</p>
<p>It also cuts recurring and non-recurring costs for the browser provider.</p>
<p>Not embedding has benefits too.</p>
<p>As one has access to more compute, one can obtain better-quality speech recognition.</p>
<p>Also, one can retain speech data to learn more about your users and to use as a source of training data.</p>
<p>In addition, the data retained is a competitive advantage over those that change to embed as they have to obtain training data some other way, which is usually time consuming and expensive.</p></div><div class="slide" role='region' aria-label="Slide 11 of 13" id="slide-11" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=11"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=11">Slide 11</a></noscript></div><div role='region'><p>With all of this and more in play, one can see that the lay of the land for browser-based speech recognition is complicated.</p></div><div class="slide" role='region' aria-label="Slide 12 of 13" id="slide-12" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=12"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=12">Slide 12</a></noscript></div><div role='region'><p>Currently, no browser implements the API as specified by the Web Speech API. The current implementations all come with asterisks, indicating that they are deficient in some way.</p>
<p>For example, using of a vendor prefix or putting limitations on how the pages can be served.</p>
<p>So as you can see, the Web Speech API is currently very much a work in progress.</p></div><div class="slide" role='region' aria-label="Slide 13 of 13" id="slide-13" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=13"><noscript><a href="https://www.w3.org/2020/Talks/mlws/kd_speech.pdf#page=13">Slide 13</a></noscript></div><div role='region'><p>Fini.</p>
<p>That's the end of my talk.</p>
<p>Thanks for listening.</p></div>