<div class="slide" role='region' aria-label="Slide 1 of 41" id="slide-1" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=1"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=1">Slide 1</a></noscript></div><div role='region'><p>My name is Jutta Treviranus and the title of my contribution to this important discussion is We Count: Fair Treatment, Disability and Machine Learning.</p></div><div class="slide" role='region' aria-label="Slide 2 of 41" id="slide-2" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=2"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=2">Slide 2</a></noscript></div><div role='region'><p>I wanna preface my talk my saying that my topic is not a specialist topic, only of concern to people interested in disability and accessibility.</p>
<p>People with lived experience of disability are the stress testers of our systems, including the web.</p>
<p>They are the canaries in the coal mine for things that will go wrong.</p>
<p>The flip side of this is that considering disability offers the innovative choices that may help us fix the cracks and shortcomings for everyone.</p></div><div class="slide" role='region' aria-label="Slide 3 of 41" id="slide-3" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=3"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=3">Slide 3</a></noscript></div><div role='region'><p>The late Stephen Hawking predicted that we were entering a dangerous time.</p>
<p>This was before COVID-19.</p>
<p>Seasoned prognosticators seemed to agree that this disruption is one of many that will come at an accelerated pace.</p>
<p>The web is host to what remains of our common conversations and deliberation.</p>
<p>Our collective move online during the pandemic means that this responsibility has become weightier.</p>
<p>Our web tools are not neutral.</p>
<p>How we design them influences their uses in subtle and blatant ways.</p>
<p>Combine web tools with the power tools of AI and we have a potent mix.</p>
<p>Machine learning may help us amplify the opportunities but we also amplify the risks.</p>
<p>Machine learning enables us to do what we are doing more efficiently and effectively.</p>
<p>Before we employ our power tools, we need to ask what do we want to amplify and automate?</p>
<p>Where are we accelerating to?</p>
<p>What is the ultimate destination if we go even faster in the direction our current practices are leading us?</p></div><div class="slide" role='region' aria-label="Slide 4 of 41" id="slide-4" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=4"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=4">Slide 4</a></noscript></div><div role='region'><p>I wanna tell you about my pivotal moment of alarm.</p></div><div class="slide" role='region' aria-label="Slide 5 of 41" id="slide-5" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=5"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=5">Slide 5</a></noscript></div><div role='region'><p>Back in 2015, I had the opportunity to test machine learning models that guide automated vehicles in intersections.</p>
<p>I tested them with an anomalous scenario, a friend of mine that propels her wheelchair backwards through an intersection, effectively but very erratically.</p>
<p>All the models chose to proceed through the intersection and effectively run my friend over.</p>
<p>Well, the developers said come back when our models are more mature and have been exposed to more data about people in wheelchairs in intersections.</p></div><div class="slide" role='region' aria-label="Slide 6 of 41" id="slide-6" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=6"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=6">Slide 6</a></noscript></div><div role='region'><p>When I retested the more mature machine learning models that had been exposed to a great deal of data about people in wheelchairs in intersections, they chose to run her over with greater confidence.</p>
<p>The data gave them confidence that people in wheelchairs move forward.</p></div><div class="slide" role='region' aria-label="Slide 7 of 41" id="slide-7" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=7"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=7">Slide 7</a></noscript></div><div role='region'><p>I realized that the power tools of AI are unable to handle diversity and complexity.</p>
<p>Unprepared for the unexpected, they replicate our own inadequacies and automate and amplify them.</p></div><div class="slide" role='region' aria-label="Slide 8 of 41" id="slide-8" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=8"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=8">Slide 8</a></noscript></div><div role='region'><p>And this is more than about automated vehicles.</p>
<p>The same pattern occurs in all automated decisions.</p>
<p>It's more than about artificial intelligence.</p></div><div class="slide" role='region' aria-label="Slide 9 of 41" id="slide-9" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=9"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=9">Slide 9</a></noscript></div><div role='region'><p>It is about how we treat small minorities and outliers.</p>
<p>I like to illustrate it in this way.</p></div><div class="slide" role='region' aria-label="Slide 10 of 41" id="slide-10" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=10"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=10">Slide 10</a></noscript></div><div role='region'><p>If we were to take all of our preferences and requirements and plot them on a multivariate scatterplot, it would look like a starburst with about 80% of the needs and requirements in 20% of the middle.</p>
<p>And the remaining 20% of the needs and requirements scattered in the 80% of the remaining space.</p></div><div class="slide" role='region' aria-label="Slide 11 of 41" id="slide-11" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=11"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=11">Slide 11</a></noscript></div><div role='region'><p>If you were to look at the dots in the middle, they're very close together, meaning they're very similar.</p>
<p>If you were to look at the dots as you move from the center, they would be further and further apart, meaning more and more different.</p></div><div class="slide" role='region' aria-label="Slide 12 of 41" id="slide-12" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=12"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=12">Slide 12</a></noscript></div><div role='region'><p>As a result of this, and in part because of Pareto and Richard Koch's 80/20 rule, design works for anyone that has a need in the middle, is difficult as you move from the middle and design doesn't work if you were out at that outer edge of our human starburst.</p></div><div class="slide" role='region' aria-label="Slide 13 of 41" id="slide-13" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=13"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=13">Slide 13</a></noscript></div><div role='region'><p>In terms of data, predictions are highly accurate if your needs are in the middle, inaccurate as you move from the middle and wrong if your needs are at the edge.</p></div><div class="slide" role='region' aria-label="Slide 14 of 41" id="slide-14" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=14"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=14">Slide 14</a></noscript></div><div role='region'><p>This pattern affects all of our systems, whether it is the design of our products and services, which thanks to Moore's law are improving in availability, reliability, functionality and cost, the opposite is true if you have marginalized needs our systems of research favor the average and ignore minority needs.</p>
<p>Our education system ranks based on the average and requires conformance, our systems of employment attempt to create replaceable workers, our democracy is driven by majority rules.</p></div><div class="slide" role='region' aria-label="Slide 15 of 41" id="slide-15" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=15"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=15">Slide 15</a></noscript></div><div role='region'><p>This not only hurts the 20% with needs at the edge, it hurts our society as a whole.</p>
<p>Because of this pattern, we have mass production, mass communication, mass marketing, a popularity push and our innovation suffers.</p>
<p>We have greater conformance, lock-in and our flexibility, extensibility, resilience and responsiveness all suffer.</p></div><div class="slide" role='region' aria-label="Slide 16 of 41" id="slide-16" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=16"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=16">Slide 16</a></noscript></div><div role='region'><p>AI ethics has received a great deal of attention lately because of the discrimination faced by many minority groups.</p>
<p>There are three main sources of a discrimination.</p>
<p>Discrimination may happen because of data gaps because people are not represented in data gathering.</p>
<p>They may have no digital traces because of digital exclusion.</p>
<p>Or inaccurate data proxies are used.</p>
<p>Data may also be misinterpreted as noise and eliminated to improve performance.</p>
<p>Secondly, there is algorithmic bias and this can result from human bias that finds its way into algorithms due to labeling analysis and interpretation that is used or it can be due to biased training data.</p>
<p>The much more fundamental discrimination faced by small minorities and outliers, including people with disabilities is the inherent bias in our statistical methods and how we treat minorities and outliers.</p></div><div class="slide" role='region' aria-label="Slide 17 of 41" id="slide-17" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=17"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=17">Slide 17</a></noscript></div><div role='region'><p>The measures we use to assess AI ethics do no cover the discrimination faced by people with disabilities.</p>
<p>The primary tools for detecting bias is to compare the treatment of bounded identity groups with a default.</p>
<p>From the data perspective, there are no common bounded identifiers for people with disabilities.</p>
<p>The only common data characteristic is distance from the mean, such that things don't work for you.</p>
<p>Therefore, many people fall through the cracks or are stranded at the edges of these bounded groups, making it even more difficult to achieve fair treatment.</p></div><div class="slide" role='region' aria-label="Slide 18 of 41" id="slide-18" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=18"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=18">Slide 18</a></noscript></div><div role='region'><p>These issues are compounded by other vulnerabilities.</p>
<p>If you're highly unique, privacy protections don't work.</p>
<p>The primary protection is de-identifications at source.</p>
<p>If you have highly unique needs, you can be re-identified.</p>
<p>If you have to request special treatment, you barter your privacy for the service.</p>
<p>People with disabilities are also most vulnerable to data abuse and misuse.</p>
<p>Because of this, we need not only privacy protections but protections against data abuse and misuse from bad actors, surveillance capitalism and the state.</p></div><div class="slide" role='region' aria-label="Slide 19 of 41" id="slide-19" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=19"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=19">Slide 19</a></noscript></div><div role='region'><p>The entire field of data science is somewhat problematic if you have a disability.</p>
<p>You face unfair treatment as subjects of data-driven decisions based on population data, barriers to participation in designing and developing data science so you can help fix it, barriers to interpreting the outcomes of data science and therefore, benefiting from it.</p>
<p>And you're subject to systemic influence or vicious cycles of discrimination.</p></div><div class="slide" role='region' aria-label="Slide 20 of 41" id="slide-20" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=20"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=20">Slide 20</a></noscript></div><div role='region'><p>How's this relevant beyond disability?</p></div><div class="slide" role='region' aria-label="Slide 21 of 41" id="slide-21" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=21"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=21">Slide 21</a></noscript></div><div role='region'><p>Traditional means of deciding, judging and planning no longer work.</p></div><div class="slide" role='region' aria-label="Slide 22 of 41" id="slide-22" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=22"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=22">Slide 22</a></noscript></div><div role='region'><p>We live in increasingly complex adaptive systems of systems.</p>
<p>These are changing and unstable, they're unpredictable, they're entangled.</p></div><div class="slide" role='region' aria-label="Slide 23 of 41" id="slide-23" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=23"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=23">Slide 23</a></noscript></div><div role='region'><p>And right now, during this pandemic, we need to navigate out of danger.</p>
<p>But we are in a complex terrain with multiple hills and valleys.</p></div><div class="slide" role='region' aria-label="Slide 24 of 41" id="slide-24" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=24"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=24">Slide 24</a></noscript></div><div role='region'><p>And because of the way we do things, we are stuck on the local optima, rather than reaching that global optima.</p>
<p>The only values are reflected in our systems are popularity and profit, meaning we can just keep going up that local hill.</p>
<p>We're optimizing towards homogeneity and conformity when we need diversity.</p>
<p>And these vicious cycles are intensifying disparity.</p></div><div class="slide" role='region' aria-label="Slide 25 of 41" id="slide-25" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=25"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=25">Slide 25</a></noscript></div><div role='region'><p>The only formula to get us out of that local optima is diversification and collaboration.</p>
<p>We need to include diverse perspectives.</p>
<p>There is no best or winning strategy.</p>
<p>We need to stop doing the same thing over and over again and we need to work together.</p></div><div class="slide" role='region' aria-label="Slide 26 of 41" id="slide-26" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=26"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=26">Slide 26</a></noscript></div><div role='region'><p>We are prone also to cobra effects or the unintended consequences of over simplistic solutions to complex problems.</p>
<p>We use linear thinking that only makes things worse.</p></div><div class="slide" role='region' aria-label="Slide 27 of 41" id="slide-27" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=27"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=27">Slide 27</a></noscript></div><div role='region'><p>We may be seeing a cobra effect right now and AI may only intensify this.</p></div><div class="slide" role='region' aria-label="Slide 28 of 41" id="slide-28" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=28"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=28">Slide 28</a></noscript></div><div role='region'><p>There's a famous Thomas Friedman graph that compels us toward greater progress to avoid economic collapse.</p>
<p>It shows us that technology's adapting at an exponential rate, while humans are adapting at a linear rate.</p></div><div class="slide" role='region' aria-label="Slide 29 of 41" id="slide-29" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=29"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=29">Slide 29</a></noscript></div><div role='region'><p>I would say the situation is worse.</p>
<p>My contention is that technology is impeding human adaptability.</p>
<p>We're cushioned from dissonance and diversity by recommender systems that recommend things liked by people like us.</p>
<p>We have search engine optimization.</p>
<p>We have a popularity bubble.</p>
<p>We have smart systems that replace human smarts and we have evidence-based decisions that favor the majority and homogeneity.</p></div><div class="slide" role='region' aria-label="Slide 30 of 41" id="slide-30" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=30"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=30">Slide 30</a></noscript></div><div role='region'><p>My recommendation is that we reconsider the 80/20 rule.</p>
<p>It came about because Pareto noticed that 80% of land in Italy was owned by 20% of the population or what he called the vital few.</p>
<p>He told the emperor of the time to ignore the 80% and attend to the vital few.</p>
<p>Koch later turned this into a formula for quick wins, saying ignore the difficult 20% who take 80% of the effort.</p></div><div class="slide" role='region' aria-label="Slide 31 of 41" id="slide-31" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=31"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=31">Slide 31</a></noscript></div><div role='region'><p>However, who are our current vital few?</p>
<p>If our goal is not greed, quick wins or gaming the system, but innovation, diverse perspectives, detecting weak signals, the difficult 20%, as Koch calls them, that occupy 80% of the unexplored terrain are the real vital few.</p></div><div class="slide" role='region' aria-label="Slide 32 of 41" id="slide-32" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=32"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=32">Slide 32</a></noscript></div><div role='region'><p>If we design with and consider the needs of those 20%, we make sure that the 80% in the middle have room to change.</p></div><div class="slide" role='region' aria-label="Slide 33 of 41" id="slide-33" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=33"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=33">Slide 33</a></noscript></div><div role='region'><p>It is out at that outer edge that we find innovation, not in the complacent middle.</p>
<p>It is also where we detect weak signals that disrupt our life.</p></div><div class="slide" role='region' aria-label="Slide 34 of 41" id="slide-34" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=34"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=34">Slide 34</a></noscript></div><div role='region'><p>But how will we measure, decide and judge if we are not using statistical average?</p></div><div class="slide" role='region' aria-label="Slide 35 of 41" id="slide-35" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=35"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=35">Slide 35</a></noscript></div><div role='region'><p>One recommendation comes from Gandhi and others.</p>
<p>“The true measure of any society can be found in how it treats its most vulnerable members”.</p>
<p>This is more than altruism.</p>
<p>It actually has scientific rationale.</p></div><div class="slide" role='region' aria-label="Slide 36 of 41" id="slide-36" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=36"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=36">Slide 36</a></noscript></div><div role='region'><p>What we need to do in our AI and in our research and in our data analytics is discover the diverse range, the edge or the periphery.</p></div><div class="slide" role='region' aria-label="Slide 37 of 41" id="slide-37" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=37"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=37">Slide 37</a></noscript></div><div role='region'><p>You may ask what about cost?</p></div><div class="slide" role='region' aria-label="Slide 38 of 41" id="slide-38" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=38"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=38">Slide 38</a></noscript></div><div role='region'><p>We've actually found that cost over time and longevity of the system works better if you plan with the edge, rather than planning for only the center, which becomes brittle and soon reaches end of life.</p></div><div class="slide" role='region' aria-label="Slide 39 of 41" id="slide-39" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=39"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=39">Slide 39</a></noscript></div><div role='region'><p>In one of the experiments we've made to level the playing field and address the needs of people with disabilities, we call our lawnmower of justice.</p>
<p>It's a very early model but what we've tried to do is to remove the top of the Gaussian curve, to take away the advantage you have by being similar to everyone else, such that the learning model needs to attend to all of the edges.</p></div><div class="slide" role='region' aria-label="Slide 40 of 41" id="slide-40" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=40"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=40">Slide 40</a></noscript></div><div role='region'><p>And what we found is that systems that value the edge of our human scatterplot adapt to change and respond to the unexpected, detect risk, transfer to new contexts, result in greater dynamic resilience and longevity, will reduce disparity and may hold the key to our survival.</p></div><div class="slide" role='region' aria-label="Slide 41 of 41" id="slide-41" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=41"><noscript><a href="https://www.w3.org/2020/Talks/mlws/jt_ai-bias.pdf#page=41">Slide 41</a></noscript></div><div role='region'><p>And I would love to continue the conversation.</p></div>