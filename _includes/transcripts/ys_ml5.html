<div class="slide" role='region' aria-label="Slide 1 of 17" id="slide-1" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=1"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=1">Slide 1</a></noscript></div><div role='region'><p>Hello, everyone.</p>
<p>My name is Yining.</p>
<p>I am an adjunct professor at New York University.</p>
<p>I work on ml5.js, a friendly machine learning JavaScript library.</p>
<p>In this talk, I will make a brief introduction to ml5.js, how it's built and discuss some challenges in the development process.</p></div><div class="slide" role='region' aria-label="Slide 2 of 17" id="slide-2" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=2"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=2">Slide 2</a></noscript></div><div role='region'><p>Ml5.js aims to make machine learning more approachable to a broad audience of artists, designers, creative coders and students.</p>
<p>The library provides access to machine learning algorithms and models in the browser, building on top of <a class=dfn>TensorFlow.js</a> with no other external dependencies.</p>
<p>Ml5.js is inspired by Processing and P5.js, whose goal is to empower people of all interests and backgrounds to learn how to program and make creative work with code.</p>
<p>However, to get started with machine learning, one needs advanced understanding of math and programming.</p>
<p>And we'd like to make this process easier so that machine learning can be something that everyone can learn, understand and explore freely.</p></div><div class="slide" role='region' aria-label="Slide 3 of 17" id="slide-3" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=3"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=3">Slide 3</a></noscript></div><div role='region'><p>What does ml5.js do?</p>
<p>It provides immediate access to pre-trained models in the browser and we can also build and train our own neural networks in the browser from scratch.</p></div><div class="slide" role='region' aria-label="Slide 4 of 17" id="slide-4" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=4"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=4">Slide 4</a></noscript></div><div role='region'><p>Here is an example of MobileNet, object detection model running in the browser with just a few lines of code.</p></div><div class="slide" role='region' aria-label="Slide 5 of 17" id="slide-5" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=5"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=5">Slide 5</a></noscript></div><div role='region'><p>Here is an example of running PoseNet to detect human poses.</p>
<p>Ml5.js also provides friendly API to get access to more human-readable results and draw those results on the canvas with, for example, p5.js.</p></div><div class="slide" role='region' aria-label="Slide 6 of 17" id="slide-6" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=6"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=6">Slide 6</a></noscript></div><div role='region'><p>This is an example of running Style Transfer model with your webcam in real time.</p></div><div class="slide" role='region' aria-label="Slide 7 of 17" id="slide-7" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=7"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=7">Slide 7</a></noscript></div><div role='region'><p>Besides running pre-trained models, we can also create our own neutral networks with ml5.js.</p>
<p>This is a demo of how we can create a neural network that classifies RGB values into common color names.</p>
<p>With ml5.js, we can load the data, create model, train it and run the model.</p>
<p>With the debug mode enabled, ml5.js can also visualize the training progress on the right-hand side.</p>
<p>It helps us to debug and improve our neural network.</p></div><div class="slide" role='region' aria-label="Slide 8 of 17" id="slide-8" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=8"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=8">Slide 8</a></noscript></div><div role='region'><p>Here is a collection of other models and methods that ml5.js provides.</p>
<p>You can learn more about them on the ml5 website.</p>
<p>Ml5 has a wide collection of image, sound and text-based models with a variety of applications, such as detecting objects, human bodies, hand poses and faces, generating text, images and drawings, implementing image translations, classifying audios, detecting pitch and analyzing words and sentences.</p>
<p>Ml5.js also provides NeuralNetwork, FeatureExtractor, KNNClassifier and KMeans as helper functions.</p></div><div class="slide" role='region' aria-label="Slide 9 of 17" id="slide-9" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=9"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=9">Slide 9</a></noscript></div><div role='region'><p>How do I use ml5.js?</p></div><div class="slide" role='region' aria-label="Slide 10 of 17" id="slide-10" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=10"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=10">Slide 10</a></noscript></div><div role='region'><p>We can run a model in the browser with ml5.js in three simple steps.</p>
<p>First, create a model.</p>
<p>Secondly, ask the model to classify or predict something based on a input, like an image or a text.</p>
<p>And step three, getting the results.</p>
<p>It also has great integration with p5.js, a JavaScript library for creating graphics and animations in the browser, which makes it easier to get inputs from webcam or microphones and also to show the outputs with canvas, image or audio.</p></div><div class="slide" role='region' aria-label="Slide 11 of 17" id="slide-11" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=11"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=11">Slide 11</a></noscript></div><div role='region'><p>How is ml5.js built?</p></div><div class="slide" role='region' aria-label="Slide 12 of 17" id="slide-12" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=12"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=12">Slide 12</a></noscript></div><div role='region'><p>Besides the core library, the ml5.js project also includes examples, documentations, guides for training and data collection, learning materials for workshops and courses.</p></div><div class="slide" role='region' aria-label="Slide 13 of 17" id="slide-13" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=13"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=13">Slide 13</a></noscript></div><div role='region'><p>Ml5.js extends the functionality of tf.js.</p>
<p>It uses tf.js models, data API, layer API and the face API.</p>
<p>Under the hood, it utilizes the CPU, <a class=dfn>WebGL</a>, or <a class=dfn>WebAssembly</a> in the browser.</p>
<p>Ml5.js provides a high-level and beginner-friendly API to users.</p></div><div class="slide" role='region' aria-label="Slide 14 of 17" id="slide-14" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=14"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=14">Slide 14</a></noscript></div><div role='region'><p>Web applications are very accessible.</p>
<p>There are a lot of web applications made by the ml5.js community.</p>
<p>Here are a few examples.</p>
<p>A Whac-A-Mole game that you can play with your webcam, a flying game where you can control your characters with your voice, an interactive story reading experiments that uses your voice as input to generate stories and drawings.</p>
<p>There are many more applications built with ml5.js that you can find at its community page.</p>
<p>People find the low effort in using existing browser API desirable.</p>
<p>For example, using webcam and microphones with the ability of rendering output easily to image, canvas, audio or text elements on the DOM.</p>
<p>So they're perfect for creative projects.</p></div><div class="slide" role='region' aria-label="Slide 15 of 17" id="slide-15" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=15"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=15">Slide 15</a></noscript></div><div role='region'><p>Webcam video, audio and mouse interactions are often used as input to models and the conversion between those formats is often a multi-step process.</p>
<p>Therefore, having native support for converting browser I/O streams to model inputs and vice versa would be very helpful.</p>
<p>For example, <a class=dfn>TensorFlow.js</a> models support HTML video or image elements as model inputs.</p></div><div class="slide" role='region' aria-label="Slide 16 of 17" id="slide-16" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=16"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=16">Slide 16</a></noscript></div><div role='region'><p>In the progress of porting models into ml5.js, the first thing to consider is the model size.</p>
<p>It needs to be small enough so we can load it into the browser.</p>
<p>Secondly, to support real-time interaction in the browser, the model needs to have low latency.</p>
<p>The last thing is the model format.</p>
<p>It should be portable to the web.</p>
<p>Here is a common workflow of porting a pre-trained model into ml5.js.</p>
<p>A model from a machine learning research paper might be implemented in other frameworks, like <a class=dfn>PyTorch</a>.</p>
<p>So first, we need to implement the model in <a class=dfn>TensorFlow</a> and train the model.</p>
<p>Then we convert the model into tf.js format with tf.js converter.</p>
<p>And lastly, port it into ml5.js to provide high-level API to users.</p>
<p>Here, the first step, which is implementing the model in <a class=dfn>TensorFlow</a> and train it is the most time-consuming step and not all the operations are supported between different machine learning frameworks.</p>
<p>Therefore, it will be very helpful to have a standard model format for the web or have a tool that can make this step easier.</p>
<p>ONNX project is making the conversion between different machine learning frameworks easier.</p></div><div class="slide" role='region' aria-label="Slide 17 of 17" id="slide-17" data-fmt="pdf" data-src="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=17"><noscript><a href="https://www.w3.org/2020/Talks/mlws/ys_ml5.pdf#page=17">Slide 17</a></noscript></div><div role='region'><p>Here are some more links about ml5.js.</p>
<p>That's all from me.</p>
<p>Thank you so much for watching.</p></div>