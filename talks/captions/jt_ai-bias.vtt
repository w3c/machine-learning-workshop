WEBVTT

slide-1
00:00:09.626 --> 00:00:11.526
<v Jutta>My name is Jutta Treviranus</v>

2
00:00:11.526 --> 00:00:13.106
and the title of my contribution

3
00:00:13.106 --> 00:00:14.486
to this important discussion

4
00:00:14.486 --> 00:00:18.366
is We Count: Fair Treatment, Disability

5
00:00:18.366 --> 00:00:19.469
and Machine Learning.

slide-2
00:00:20.766 --> 00:00:22.586
I wanna preface my talk my saying

7
00:00:22.586 --> 00:00:25.356
that my topic is not a specialist topic,

8
00:00:25.356 --> 00:00:27.296
only of concern to people interested

9
00:00:27.296 --> 00:00:29.706
in disability and accessibility.

10
00:00:29.706 --> 00:00:31.836
People with lived experience of disability

11
00:00:31.836 --> 00:00:34.316
are the stress testers of our systems,

12
00:00:34.316 --> 00:00:35.796
including the web.

13
00:00:35.796 --> 00:00:37.516
They are the canaries in the coal mine

14
00:00:37.516 --> 00:00:39.656
for things that will go wrong.

15
00:00:39.656 --> 00:00:40.866
The flip side of this

16
00:00:40.866 --> 00:00:42.606
is that considering disability

17
00:00:42.606 --> 00:00:44.266
offers the innovative choices

18
00:00:44.266 --> 00:00:46.626
that may help us fix the cracks

19
00:00:46.626 --> 00:00:48.659
and shortcomings for everyone.

slide-3
00:00:50.166 --> 00:00:52.816
The late Stephen Hawking predicted

21
00:00:52.816 --> 00:00:55.376
that we were entering a dangerous time.

22
00:00:55.376 --> 00:00:57.876
This was before COVID-19.

23
00:00:57.876 --> 00:01:01.766
Seasoned prognosticators seemed to agree

24
00:01:01.766 --> 00:01:03.516
that this disruption is one of many

25
00:01:03.516 --> 00:01:06.926
that will come at an accelerated pace.

26
00:01:06.926 --> 00:01:08.736
The web is host to what remains

27
00:01:08.736 --> 00:01:11.756
of our common conversations and deliberation.

28
00:01:11.756 --> 00:01:14.506
Our collective move online during the pandemic means

29
00:01:14.506 --> 00:01:17.556
that this responsibility has become weightier.

30
00:01:17.556 --> 00:01:19.386
Our web tools are not neutral.

31
00:01:19.386 --> 00:01:22.166
How we design them influences their uses

32
00:01:22.166 --> 00:01:24.696
in subtle and blatant ways.

33
00:01:24.696 --> 00:01:28.116
Combine web tools with the power tools of AI

34
00:01:28.116 --> 00:01:30.036
and we have a potent mix.

35
00:01:30.036 --> 00:01:33.557
Machine learning may help us amplify the opportunities

36
00:01:33.557 --> 00:01:36.146
but we also amplify the risks.

37
00:01:36.146 --> 00:01:37.477
Machine learning enables us

38
00:01:37.477 --> 00:01:41.436
to do what we are doing more efficiently and effectively.

39
00:01:41.436 --> 00:01:43.966
Before we employ our power tools,

40
00:01:43.966 --> 00:01:48.216
we need to ask what do we want to amplify and automate?

41
00:01:48.216 --> 00:01:50.616
Where are we accelerating to?

42
00:01:50.616 --> 00:01:52.376
What is the ultimate destination

43
00:01:52.376 --> 00:01:54.328
if we go even faster in the direction

44
00:01:54.328 --> 00:01:57.139
our current practices are leading us?

slide-4
00:01:58.666 --> 00:02:02.296
I wanna tell you about my pivotal moment of alarm.

slide-5
00:02:02.296 --> 00:02:06.126
Back in 2015, I had the opportunity

47
00:02:06.126 --> 00:02:08.206
to test machine learning models

48
00:02:08.206 --> 00:02:11.156
that guide automated vehicles in intersections.

49
00:02:11.156 --> 00:02:13.366
I tested them with an anomalous scenario,

50
00:02:13.366 --> 00:02:16.456
a friend of mine that propels her wheelchair backwards

51
00:02:16.456 --> 00:02:17.566
through an intersection,

52
00:02:17.566 --> 00:02:20.156
effectively but very erratically.

53
00:02:20.156 --> 00:02:23.178
All the models chose to proceed through the intersection

54
00:02:23.178 --> 00:02:26.286
and effectively run my friend over.

55
00:02:26.286 --> 00:02:28.056
Well, the developers said come back

56
00:02:28.056 --> 00:02:30.306
when our models are more mature

57
00:02:30.306 --> 00:02:32.686
and have been exposed to more data about people

58
00:02:32.686 --> 00:02:35.256
in wheelchairs in intersections.

slide-6
00:02:35.256 --> 00:02:39.015
When I retested the more mature machine learning models

60
00:02:39.015 --> 00:02:41.836
that had been exposed to a great deal of data

61
00:02:41.836 --> 00:02:43.969
about people in wheelchairs in intersections,

62
00:02:43.969 --> 00:02:47.566
they chose to run her over with greater confidence.

63
00:02:47.566 --> 00:02:49.226
The data gave them confidence

64
00:02:49.226 --> 00:02:51.548
that people in wheelchairs move forward.

slide-7
00:02:51.548 --> 00:02:55.026
I realized that the power tools of AI

66
00:02:55.026 --> 00:02:58.076
are unable to handle diversity and complexity.

67
00:02:58.076 --> 00:03:00.366
Unprepared for the unexpected,

68
00:03:00.366 --> 00:03:02.586
they replicate our own inadequacies

69
00:03:02.586 --> 00:03:04.996
and automate and amplify them.

slide-8
00:03:04.996 --> 00:03:07.656
And this is more than about automated vehicles.

71
00:03:07.656 --> 00:03:11.126
The same pattern occurs in all automated decisions.

72
00:03:11.126 --> 00:03:14.069
It's more than about artificial intelligence.

slide-9
00:03:15.676 --> 00:03:20.026
It is about how we treat small minorities and outliers.

74
00:03:20.026 --> 00:03:21.896
I like to illustrate it in this way.

slide-10
00:03:21.896 --> 00:03:24.506
If we were to take all of our preferences

76
00:03:24.506 --> 00:03:26.846
and requirements and plot them

77
00:03:26.846 --> 00:03:29.726
on a multivariate scatterplot,

78
00:03:29.726 --> 00:03:31.536
it would look like a starburst

79
00:03:31.536 --> 00:03:33.846
with about 80% of the needs

80
00:03:33.846 --> 00:03:37.386
and requirements in 20% of the middle.

81
00:03:37.386 --> 00:03:39.646
And the remaining 20% of the needs

82
00:03:39.646 --> 00:03:42.486
and requirements scattered in the 80%

83
00:03:42.486 --> 00:03:44.846
of the remaining space.

slide-11
00:03:44.846 --> 00:03:47.576
If you were to look at the dots in the middle,

85
00:03:47.576 --> 00:03:48.706
they're very close together,

86
00:03:48.706 --> 00:03:50.116
meaning they're very similar.

87
00:03:50.116 --> 00:03:53.232
If you were to look at the dots as you move from the center,

88
00:03:53.232 --> 00:03:55.336
they would be further and further apart,

89
00:03:55.336 --> 00:03:57.169
meaning more and more different.

slide-12
00:03:59.136 --> 00:04:00.506
As a result of this,

91
00:04:00.506 --> 00:04:04.846
and in part because of Pareto and Richard Koch's 80/20 rule,

92
00:04:04.846 --> 00:04:07.126
design works for anyone that has a need

93
00:04:07.126 --> 00:04:07.959
in the middle,

94
00:04:07.959 --> 00:04:10.016
is difficult as you move from the middle

95
00:04:10.016 --> 00:04:11.693
and design doesn't work

96
00:04:11.693 --> 00:04:14.949
if you were out at that outer edge of our human starburst.

97
00:04:16.436 --> 00:04:17.566
In terms of data,

98
00:04:17.566 --> 00:04:19.736
predictions are highly accurate if your needs

99
00:04:19.736 --> 00:04:20.569
are in the middle,

100
00:04:20.569 --> 00:04:22.265
inaccurate as you move from the middle

101
00:04:22.265 --> 00:04:24.839
and wrong if your needs are at the edge.

slide-13
00:04:26.116 --> 00:04:28.656
This pattern affects all of our systems,

103
00:04:28.656 --> 00:04:31.468
whether it is the design of our products and services,

104
00:04:31.468 --> 00:04:34.146
which thanks to Moore's law are improving

105
00:04:34.146 --> 00:04:37.469
in availability, reliability, functionality and cost,

106
00:04:37.469 --> 00:04:40.792
the opposite is true if you have marginalized needs

107
00:04:40.792 --> 00:04:43.916
our systems of research favor the average

108
00:04:43.916 --> 00:04:45.306
and ignore minority needs.

109
00:04:45.306 --> 00:04:48.436
Our education system ranks based

110
00:04:48.436 --> 00:04:50.592
on the average and requires conformance,

111
00:04:50.592 --> 00:04:52.856
our systems of employment attempt

112
00:04:52.856 --> 00:04:55.366
to create replaceable workers,

113
00:04:55.366 --> 00:04:58.679
our democracy is driven by majority rules.

114
00:05:00.236 --> 00:05:02.706
This not only hurts the 20%

115
00:05:02.706 --> 00:05:06.546
with needs at the edge, it hurts our society as a whole.

116
00:05:06.546 --> 00:05:09.886
Because of this pattern, we have mass production,

117
00:05:09.886 --> 00:05:11.907
mass communication, mass marketing,

118
00:05:11.907 --> 00:05:13.519
a popularity push

119
00:05:13.519 --> 00:05:16.096
and our innovation suffers.

120
00:05:16.096 --> 00:05:17.976
We have greater conformance, lock-in

121
00:05:17.976 --> 00:05:19.986
and our flexibility, extensibility,

122
00:05:19.986 --> 00:05:22.899
resilience and responsiveness all suffer.

slide-14
00:05:24.966 --> 00:05:27.056
AI ethics has received a great deal

124
00:05:27.056 --> 00:05:29.996
of attention lately because of the discrimination faced

125
00:05:29.996 --> 00:05:31.854
by many minority groups.

126
00:05:31.854 --> 00:05:34.979
There are three main sources of a discrimination.

127
00:05:35.856 --> 00:05:38.276
Discrimination may happen because of data gaps

128
00:05:38.276 --> 00:05:41.726
because people are not represented in data gathering.

129
00:05:41.726 --> 00:05:43.766
They may have no digital traces

130
00:05:43.766 --> 00:05:45.770
because of digital exclusion.

131
00:05:45.770 --> 00:05:49.736
Or inaccurate data proxies are used.

132
00:05:49.736 --> 00:05:52.336
Data may also be misinterpreted as noise

133
00:05:52.336 --> 00:05:55.099
and eliminated to improve performance.

134
00:05:56.076 --> 00:05:59.056
Secondly, there is algorithmic bias

135
00:05:59.056 --> 00:06:02.456
and this can result from human bias that finds its way

136
00:06:02.456 --> 00:06:05.776
into algorithms due to labeling analysis

137
00:06:05.776 --> 00:06:07.610
and interpretation that is used

138
00:06:07.610 --> 00:06:11.379
or it can be due to biased training data.

139
00:06:12.366 --> 00:06:15.496
The much more fundamental discrimination faced

140
00:06:15.496 --> 00:06:17.496
by small minorities and outliers,

141
00:06:17.496 --> 00:06:19.088
including people with disabilities

142
00:06:19.088 --> 00:06:22.446
is the inherent bias in our statistical methods

143
00:06:22.446 --> 00:06:24.989
and how we treat minorities and outliers.

slide-15
00:06:26.726 --> 00:06:29.836
The measures we use to assess AI ethics

145
00:06:29.836 --> 00:06:31.876
do no cover the discrimination faced

146
00:06:31.876 --> 00:06:33.368
by people with disabilities.

147
00:06:33.368 --> 00:06:36.250
The primary tools for detecting bias

148
00:06:36.250 --> 00:06:39.836
is to compare the treatment of bounded identity groups

149
00:06:39.836 --> 00:06:41.346
with a default.

150
00:06:41.346 --> 00:06:42.686
From the data perspective,

151
00:06:42.686 --> 00:06:45.060
there are no common bounded identifiers

152
00:06:45.060 --> 00:06:47.090
for people with disabilities.

153
00:06:47.090 --> 00:06:49.344
The only common data characteristic

154
00:06:49.344 --> 00:06:51.206
is distance from the mean,

155
00:06:51.206 --> 00:06:53.466
such that things don't work for you.

156
00:06:53.466 --> 00:06:55.576
Therefore, many people fall through the cracks

157
00:06:55.576 --> 00:06:58.716
or are stranded at the edges of these bounded groups,

158
00:06:58.716 --> 00:07:00.487
making it even more difficult

159
00:07:00.487 --> 00:07:04.379
to achieve fair treatment.

slide-16
00:07:06.316 --> 00:07:09.356
These issues are compounded by other vulnerabilities.

161
00:07:09.356 --> 00:07:12.176
If you're highly unique, privacy protections don't work.

162
00:07:12.176 --> 00:07:17.176
The primary protection is de-identifications at source.

163
00:07:17.626 --> 00:07:19.689
If you have highly unique needs,

164
00:07:20.716 --> 00:07:22.379
you can be re-identified.

165
00:07:22.379 --> 00:07:25.372
If you have to request special treatment,

166
00:07:25.372 --> 00:07:28.426
you barter your privacy for the service.

167
00:07:28.426 --> 00:07:31.196
People with disabilities are also most vulnerable

168
00:07:31.196 --> 00:07:33.316
to data abuse and misuse.

169
00:07:33.316 --> 00:07:35.837
Because of this, we need not only privacy protections

170
00:07:35.837 --> 00:07:38.326
but protections against data abuse

171
00:07:38.326 --> 00:07:40.626
and misuse from bad actors,

172
00:07:40.626 --> 00:07:42.919
surveillance capitalism and the state.

slide-17
00:07:45.886 --> 00:07:47.826
The entire field of data science

174
00:07:47.826 --> 00:07:50.686
is somewhat problematic if you have a disability.

175
00:07:50.686 --> 00:07:52.306
You face unfair treatment

176
00:07:52.306 --> 00:07:54.436
as subjects of data-driven decisions based

177
00:07:54.436 --> 00:07:55.839
on population data,

178
00:07:55.839 --> 00:07:57.876
barriers to participation

179
00:07:57.876 --> 00:07:59.996
in designing and developing data science

180
00:07:59.996 --> 00:08:01.616
so you can help fix it,

181
00:08:01.616 --> 00:08:03.307
barriers to interpreting the outcomes

182
00:08:03.307 --> 00:08:06.416
of data science and therefore, benefiting from it.

183
00:08:06.416 --> 00:08:08.956
And you're subject to systemic influence

184
00:08:08.956 --> 00:08:11.239
or vicious cycles of discrimination.

slide-18
00:08:13.336 --> 00:08:15.869
How's this relevant beyond disability?

slide-19
00:08:18.496 --> 00:08:20.146
Traditional means of deciding,

187
00:08:20.146 --> 00:08:22.949
judging and planning no longer work.

slide-20
00:08:24.656 --> 00:08:29.426
We live in increasingly complex adaptive systems of systems.

189
00:08:29.426 --> 00:08:31.326
These are changing and unstable,

190
00:08:31.326 --> 00:08:33.699
they're unpredictable, they're entangled.

slide-21
00:08:35.316 --> 00:08:37.476
And right now, during this pandemic,

192
00:08:37.476 --> 00:08:39.225
we need to navigate out of danger.

193
00:08:39.225 --> 00:08:42.496
But we are in a complex terrain

194
00:08:42.496 --> 00:08:45.191
with multiple hills and valleys.

slide-22
00:08:45.191 --> 00:08:47.546
And because of the way we do things,

196
00:08:47.546 --> 00:08:49.976
we are stuck on the local optima,

197
00:08:49.976 --> 00:08:52.665
rather than reaching that global optima.

198
00:08:52.665 --> 00:08:55.076
The only values are reflected

199
00:08:55.076 --> 00:08:57.726
in our systems are popularity and profit,

200
00:08:57.726 --> 00:09:01.086
meaning we can just keep going up that local hill.

201
00:09:01.086 --> 00:09:03.841
We're optimizing towards homogeneity and conformity

202
00:09:03.841 --> 00:09:06.464
when we need diversity.

203
00:09:06.464 --> 00:09:10.549
And these vicious cycles are intensifying disparity.

slide-23
00:09:12.756 --> 00:09:16.596
The only formula to get us out of that local optima

205
00:09:16.596 --> 00:09:20.326
is diversification and collaboration.

206
00:09:20.326 --> 00:09:22.265
We need to include diverse perspectives.

207
00:09:22.265 --> 00:09:25.956
There is no best or winning strategy.

208
00:09:25.956 --> 00:09:28.146
We need to stop doing the same thing over

209
00:09:28.146 --> 00:09:31.279
and over again and we need to work together.

slide-24
00:09:33.376 --> 00:09:36.003
We are prone also to cobra effects

211
00:09:36.003 --> 00:09:38.276
or the unintended consequences

212
00:09:38.276 --> 00:09:41.736
of over simplistic solutions to complex problems.

213
00:09:41.736 --> 00:09:44.879
We use linear thinking that only makes things worse.

slide-25
00:09:46.163 --> 00:09:49.316
We may be seeing a cobra effect right now

215
00:09:49.316 --> 00:09:52.780
and AI may only intensify this.

slide-26
00:09:52.780 --> 00:09:55.266
There's a famous Thomas Friedman graph

217
00:09:55.266 --> 00:09:57.536
that compels us toward greater progress

218
00:09:57.536 --> 00:09:59.796
to avoid economic collapse.

219
00:09:59.796 --> 00:10:01.778
It shows us that technology's adapting

220
00:10:01.778 --> 00:10:03.546
at an exponential rate,

221
00:10:03.546 --> 00:10:06.119
while humans are adapting at a linear rate.

slide-27
00:10:07.996 --> 00:10:10.210
I would say the situation is worse.

223
00:10:10.210 --> 00:10:12.016
My contention is that technology

224
00:10:12.016 --> 00:10:14.639
is impeding human adaptability.

225
00:10:14.639 --> 00:10:17.053
We're cushioned from dissonance and diversity

226
00:10:17.053 --> 00:10:18.906
by recommender systems

227
00:10:18.906 --> 00:10:23.666
that recommend things liked by people like us.

228
00:10:23.666 --> 00:10:25.594
We have search engine optimization.

229
00:10:25.594 --> 00:10:28.410
We have a popularity bubble.

230
00:10:28.410 --> 00:10:32.936
We have smart systems that replace human smarts

231
00:10:32.936 --> 00:10:34.976
and we have evidence-based decisions

232
00:10:34.976 --> 00:10:37.579
that favor the majority and homogeneity.

slide-28
00:10:39.146 --> 00:10:43.266
My recommendation is that we reconsider the 80/20 rule.

234
00:10:43.266 --> 00:10:45.366
It came about because Pareto noticed

235
00:10:45.366 --> 00:10:47.106
that 80% of land in Italy

236
00:10:47.106 --> 00:10:49.916
was owned by 20% of the population

237
00:10:49.916 --> 00:10:51.786
or what he called the vital few.

238
00:10:51.786 --> 00:10:53.476
He told the emperor of the time

239
00:10:53.476 --> 00:10:54.736
to ignore the 80%

240
00:10:54.736 --> 00:10:57.246
and attend to the vital few.

241
00:10:57.246 --> 00:10:59.726
Koch later turned this into a formula

242
00:10:59.726 --> 00:11:03.676
for quick wins, saying ignore the difficult 20%

243
00:11:03.676 --> 00:11:05.919
who take 80% of the effort.

slide-29
00:11:08.136 --> 00:11:11.596
However, who are our current vital few?

245
00:11:11.596 --> 00:11:13.656
If our goal is not greed, quick wins

246
00:11:13.656 --> 00:11:16.640
or gaming the system, but innovation,

247
00:11:16.640 --> 00:11:20.140
diverse perspectives, detecting weak signals,

248
00:11:20.140 --> 00:11:22.995
the difficult 20%, as Koch calls them,

249
00:11:22.995 --> 00:11:26.510
that occupy 80% of the unexplored terrain

250
00:11:26.510 --> 00:11:28.789
are the real vital few.

slide-30
00:11:31.086 --> 00:11:33.746
If we design with and consider the needs

252
00:11:33.746 --> 00:11:36.418
of those 20%, we make sure that the 80%

253
00:11:36.418 --> 00:11:39.269
in the middle have room to change.

slide-31
00:11:39.269 --> 00:11:41.326
It is out at that outer edge

255
00:11:41.326 --> 00:11:42.726
that we find innovation,

256
00:11:42.726 --> 00:11:44.256
not in the complacent middle.

257
00:11:44.256 --> 00:11:46.530
It is also where we detect weak signals

258
00:11:46.530 --> 00:11:48.439
that disrupt our life.

slide-32
00:11:49.796 --> 00:11:52.378
But how will we measure, decide and judge

260
00:11:52.378 --> 00:11:55.809
if we are not using statistical average?

slide-33
00:11:58.186 --> 00:12:01.713
One recommendation comes from Gandhi and others.

262
00:12:01.713 --> 00:12:04.353
“The true measure of any society can be found

263
00:12:04.353 --> 00:12:08.316
"in how it treats its most vulnerable members”.

264
00:12:08.316 --> 00:12:09.964
This is more than altruism.

265
00:12:09.964 --> 00:12:13.039
It actually has scientific rationale.

slide-34
00:12:14.666 --> 00:12:17.136
What we need to do in our AI

267
00:12:17.136 --> 00:12:19.346
and in our research and in our data analytics

268
00:12:19.346 --> 00:12:22.626
is discover the diverse range,

269
00:12:22.626 --> 00:12:24.469
the edge or the periphery.

slide-35
00:12:26.446 --> 00:12:28.539
You may ask what about cost?

slide-36
00:12:29.476 --> 00:12:31.750
We've actually found that cost over time

272
00:12:31.750 --> 00:12:35.186
and longevity of the system works better

273
00:12:35.186 --> 00:12:37.696
if you plan with the edge,

274
00:12:37.696 --> 00:12:39.696
rather than planning for only the center,

275
00:12:39.696 --> 00:12:43.269
which becomes brittle and soon reaches end of life.

slide-37
00:12:45.126 --> 00:12:46.712
In one of the experiments we've made

277
00:12:46.712 --> 00:12:48.696
to level the playing field

278
00:12:48.696 --> 00:12:50.717
and address the needs of people with disabilities,

279
00:12:50.717 --> 00:12:54.426
we call our lawnmower of justice.

280
00:12:54.426 --> 00:12:55.639
It's a very early model

281
00:12:55.639 --> 00:12:57.039
but what we've tried to do

282
00:12:57.039 --> 00:13:00.450
is to remove the top of the Gaussian curve,

283
00:13:00.450 --> 00:13:04.346
to take away the advantage you have by being similar

284
00:13:04.346 --> 00:13:05.396
to everyone else,

285
00:13:05.396 --> 00:13:07.046
such that the learning model needs

286
00:13:07.046 --> 00:13:09.529
to attend to all of the edges.

slide-38
00:13:10.456 --> 00:13:12.836
And what we found is that systems

288
00:13:12.836 --> 00:13:15.623
that value the edge of our human scatterplot adapt

289
00:13:15.623 --> 00:13:18.156
to change and respond to the unexpected,

290
00:13:18.156 --> 00:13:20.677
detect risk, transfer to new contexts,

291
00:13:20.677 --> 00:13:23.970
result in greater dynamic resilience and longevity,

292
00:13:23.970 --> 00:13:25.720
will reduce disparity

293
00:13:25.720 --> 00:13:28.329
and may hold the key to our survival.

slide-39
00:13:29.386 --> 00:13:31.749
And I would love to continue the conversation.

