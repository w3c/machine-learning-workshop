WEBVTT

slide-1
00:08.160 --> 00:08.940
Slide One

00:08.940 --> 00:11.660
First I would introduce myself briefly.

00:11.660 --> 00:15.900
I'm Zelun Chen from Netease and I'm a front-end and client development engineer.

00:15.900 --> 00:17.460
Today, the topic of my presentation is

00:17.460 --> 00:22.660
An Online Virtual Character Web Meeting With Expression Enhance Power By Machine Learning

00:22.660 --> 00:24.460
where we use WebAssembly

00:24.460 --> 00:26.940
to run Machine Learning Algorithm on the browser.

00:26.940 --> 00:28.700
Now I'll give my presentation.

00:30.820 --> 00:32.420
Slide Two.

slide-2
00:32.420 --> 00:35.700
First, let me explain the background of our project.

00:35.700 --> 00:41.899
Since the pandemic has caused great inconvenience for holding large conferences,

00:41.899 --> 00:46.900
we are thinking about building a meeting scene within our game scene

00:46.900 --> 00:51.580
so that the lecturer and the audience can join the conference via virtual images

00:51.580 --> 00:54.700
and the online conference could be vivid and immersive.

00:54.700 --> 00:56.340
As is shown in this picture,

00:56.340 --> 00:59.500
this is our meeting scene that we have built.

00:59.500 --> 01:01.300
There are audience seats

01:01.300 --> 01:03.380
and there is a podium.

01:03.380 --> 01:06.100
The lecturer can deliver a speech on the podium

01:06.100 --> 01:09.580
and display his or her presentation using the screen in the middle of it.

01:09.580 --> 01:12.700
In the lower left corner is the virtual image of the lecturer.

01:12.700 --> 01:16.420
So far, the faces of the audience and lecturers have been stiff

01:16.420 --> 01:18.140
without rich facial expressions.

01:18.140 --> 01:22.460
That's not quite what we're looking for in our immersive experience

01:22.460 --> 01:25.100
Now let me introduce our framework.

01:26.200 --> 01:28.780
Slide Three.

slide-3
01:28.780 --> 01:30.740
Our framework is as follows:

01:30.740 --> 01:34.500
First, the audience and the lecturer go to the web page in their browser

01:34.500 --> 01:38.420
and connect to a remote game client via WebRTC.

01:38.420 --> 01:44.100
Then their sounds can be transmitted through WebRTC from their local microphones to the game's audio module

01:44.100 --> 01:47.580
to allow lectures and Q&amp;As.

01:47.580 --> 01:52.500
After building the online meeting scene in this way,

01:52.500 --> 01:56.900
we've been thinking that a successful meeting takes more than just these basic elements.

01:56.900 --> 02:03.820
We also need to enhance interactions among attendees to create a vivid and immersive meeting,

02:03.820 --> 02:07.420
for example, to allow the audience to turn around and see the look on other people's faces,

02:07.420 --> 02:08.860
or to say hello to each other,

02:08.860 --> 02:11.381
or even to see the face of the lecturer.

02:11.382 --> 02:14.460
After thinking for some time,

02:14.460 --> 02:21.579
it occurs to us that we can use the browser to capture faces from their cameras and transmit them to virtual images

02:21.579 --> 02:23.260
so that everyone can see.

02:23.260 --> 02:28.900
Our algorithm group happens to have a machine-learning-based library of emoji transmission,

02:28.900 --> 02:31.380
so we were wondering if we could run this library on our browser.

02:34.000 --> 02:35.260
Slide Four.

slide-4
02:35.260 --> 02:40.420
So here's how we're going to run this whole algorithmic engineering.

02:40.420 --> 02:44.340
First we need to use camera to capture video

02:44.340 --> 02:52.340
and send it to our algorithm to get model node parameters.

02:52.340 --> 02:59.300
Then we render these node parameters onto this virtual image in browser

02:59.300 --> 03:05.140
and repeat this step so as to convert real-time facial data into a web model.

03:05.140 --> 03:11.340
After that, we were thinking about how we can run this engineering on the Web.

03:12.340 --> 03:14.980
Slide Five.

slide-5
03:14.980 --> 03:19.740
As our machine learning algorithm is based on C++

03:19.740 --> 03:23.220
and only uses Opencv library and a machine learning inference engine internally,

03:23.220 --> 03:27.780
all we need to do is to run this C++ code on Web.

03:27.780 --> 03:29.260
So we came up with three solutions.

03:29.260 --> 03:35.260
The first one is to rewrite our source code with Javascript

03:35.260 --> 03:40.460
referencing OpencvJs library and the machine learning Inference engine Js lib.

03:40.460 --> 03:44.140
But this requires that we know both C++ and JS development

03:44.140 --> 03:47.620
and the essential difference between them,

03:47.620 --> 03:49.740
which is a lot of work.

03:49.740 --> 03:51.900
So we didn't adopt this solution in the end.

03:51.980 --> 03:56.140
The second solution is to deploy algorithmic engineering on the server

03:56.140 --> 03:58.420
and to invoke it through back end Api interface.

03:58.420 --> 04:02.540
But since we need real-time facial data to build the model,

04:02.540 --> 04:05.380
there will be network request time latency,

04:05.380 --> 04:08.100
so we didn't adopt this solution, either.

04:08.100 --> 04:13.180
The third solution is to compile the entire C++ library to WebAssembly

04:13.180 --> 04:15.220
and directly run it on the browser.

04:15.220 --> 04:18.340
In this way, the problems of the first two solutions won't occur.

04:18.340 --> 04:21.140
Eventually, we adopted the third solution.

04:23.200 --> 04:24.180
Slide Six.

slide-6
04:24.980 --> 04:30.600
So here is a routine way of compiling C++ to WebAssembly

04:30.600 --> 04:32.540
as shown in the current page.

04:32.540 --> 04:37.200
We pack it up as a WASM file and run it on our browser.

04:37.200 --> 04:42.180
Here are the results we got.

04:42.180 --> 04:45.700
The first is how it works on the browser.

05:06.420 --> 05:11.180
As you can see, it doesn't work very well on the browser.

05:11.180 --> 05:15.100
It takes about two seconds to convert facial data into model data,

05:15.100 --> 05:17.660
so it looks a bit laggy.

05:17.660 --> 05:20.220
Then let's take a look at what we did on Unity,

05:20.220 --> 05:23.600
which is what we expect to see.

05:33.940 --> 05:34.420
Slide Seven.

slide-7
05:34.420 --> 05:37.620
We can tell by comparing the two videos

05:37.620 --> 05:40.660
that our engineering doesn't work very well on WebAssembly.

05:40.660 --> 05:47.580
So here we raise a couple of questions about running WebAssembly on Web in our algorithmic engineering

05:47.580 --> 05:48.820
to discuss with you.

05:48.820 --> 05:51.420
First of all, as a front-end development engineer,

05:51.420 --> 05:54.500
when packing the entire C++ algorithm engineering,

05:54.500 --> 05:59.460
you need to know a lot of knowledge of CMake, CLang, and Cross Compile, and these libraries' source code,

05:59.460 --> 06:04.860
because some of these methods from outside libraries cannot run on WebAssembly.

06:04.860 --> 06:06.980
And here we have an idea

06:06.980 --> 06:10.140
that maybe we can build an library environment like Npm

06:10.140 --> 06:15.620
to version the LLVM-complied code library written by a developer

06:15.620 --> 06:21.860
so that WebAssembly developers can use these libraries easily whether they have knowledge of C++ or not.

06:21.860 --> 06:26.740
Second, since most of our inference libraries support OpenMp

06:26.740 --> 06:28.620
instead of PThread,

06:28.620 --> 06:33.180
we cannot use WebAssembly's multi threading to optimize.

06:33.180 --> 06:38.980
There are also biological differences to be dealt with.

06:38.980 --> 06:45.200
Third, we have encountered bad performance on matrix calculation,

06:45.200 --> 06:50.980
and would love to hear if you have any suggestions to optimize it.

06:50.980 --> 06:59.660
Fourth, our WASM file is a source code that can be acquired through reverse engineering and decompilation in browser,

06:59.660 --> 07:03.460
which lacks support on encrypt solution and does not guarantee the safety of our algorithmic engineering.

07:03.460 --> 07:06.900
Do you have any possible solutions to this?

07:06.900 --> 07:10.380
Those are the four problems that we're dealing with.

07:10.380 --> 07:17.980
We have come up with some solutions to improve its performance.

07:17.980 --> 07:23.460
For example, we first thought about using some efficient Javascript libraries

07:23.460 --> 07:28.500
and use EM_JS to call Javascript via WebAssembly.

07:28.500 --> 07:35.260
This is certainly not a good solution as it requires communication between WASM and JS files

07:35.260 --> 07:38.140
and those that call this library all need to be modified.

07:38.140 --> 07:43.580
Can we use Web common algorithm library to write some web development methods

07:43.580 --> 07:46.700
that automatically call underlying ES_JM

07:46.700 --> 07:49.600
when the environment is WebAssembly?

07:49.600 --> 07:56.260
Second, we tried to use SIMD experimental features

07:56.260 --> 07:58.140
on the latest browser.

07:58.140 --> 08:00.300
However, it didn't meet our expectations.

08:00.300 --> 08:04.200
First of all, the audience and the lecturer may not be using the most up-to-date browser.

08:04.200 --> 08:08.540
Second, it doesn't make much difference to our computational efficiency.

08:11.860 --> 08:12.220
Slide Eight.

slide-8
08:12.220 --> 08:17.200
Do you have any suggestions or opinions?

08:17.200 --> 08:18.100
Please feel free to tell us, thank you.


